{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n",
      "WARNING:tensorflow:From C:\\Users\\karti\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import librosa\n",
    "import tflearn\n",
    "import tensorflow as tf\n",
    "import librosa.display\n",
    "import IPython.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as ms\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/karti/Speech/LibriSpeech/dev-clean/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y=[]\n",
    "f = open(\"y.txt\", \"r\")\n",
    "for x in f:\n",
    "  new_y.append(int(x.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2703"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y = np.array(new_y).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('mfccs.pkl', 'wb') as f:\n",
    "#     pickle.dump(mfccs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import preprocessing\n",
    "# le = preprocessing.LabelEncoder()\n",
    "# le.fit(new_y)\n",
    "# res=le.transform(new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(new_y)\n",
    "res=enc.transform(new_y).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "new_mfccs=[]\n",
    "with open('mfccs.pkl', 'rb') as f:\n",
    "    new_mfccs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2703"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_mfccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni=[]\n",
    "for i in new_y:\n",
    "    if(i not in uni):\n",
    "        uni.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-320.3857\n"
     ]
    }
   ],
   "source": [
    "print((new_mfccs[0][0]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2703"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_mfccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-422.61273   , -420.83978   , -421.63156   , ..., -474.38013   ,\n",
       "        -474.8237    , -455.48975   ],\n",
       "       [  47.226917  ,   46.655884  ,   49.06836   , ...,   48.494804  ,\n",
       "          46.773216  ,   48.03399   ],\n",
       "       [ -28.221333  ,  -29.218151  ,  -22.760973  , ...,    9.897391  ,\n",
       "           8.224331  ,  -11.62133   ],\n",
       "       ...,\n",
       "       [  -6.1200995 ,   -6.310774  ,   -4.5463758 , ...,   -6.9940376 ,\n",
       "          -5.34544   ,    3.0775084 ],\n",
       "       [  10.111799  ,   13.743115  ,   21.587517  , ...,    0.93357164,\n",
       "          -2.2579224 ,   -6.3719716 ],\n",
       "       [   3.061989  ,    9.477272  ,   14.413259  , ...,   11.6231785 ,\n",
       "           6.7680616 ,    5.625402  ]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_mfccs[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_mean_mfccs=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "464"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_mfccs[50][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    }
   ],
   "source": [
    "# find max\n",
    "min_len=len(new_mfccs[0][0])\n",
    "t=0\n",
    "for i in new_mfccs:\n",
    "    t+=1\n",
    "    if(len(i[0])<min_len):\n",
    "        min_len=len(i[0])\n",
    "print(min_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1406\n"
     ]
    }
   ],
   "source": [
    "# find max\n",
    "max_len=0\n",
    "t=0\n",
    "for i in new_mfccs:\n",
    "    t+=1\n",
    "    if(len(i[0])>max_len):\n",
    "        max_len=len(i[0])\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "734"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mid=(min_len+max_len)//2\n",
    "mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "734"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padding_mean_mfccs=[]\n",
    "\n",
    "for i in range(len(new_mfccs)):\n",
    "    fill=[]\n",
    "    for j in range (len(new_mfccs[i])):\n",
    "        inner_fill=[]\n",
    "        loop=min(len(new_mfccs[i][j]), mid);\n",
    "        for k in range(loop):\n",
    "            inner_fill.append(new_mfccs[i][j][k])\n",
    "        pad_mean=new_mfccs[i][j].mean()\n",
    "        for k in range(mid-loop):\n",
    "            inner_fill.append(pad_mean)\n",
    "        fill.append(inner_fill)\n",
    "#     print(fill)\n",
    "    padding_mean_mfccs.append(fill)\n",
    "#     print(len(padding0_mfccs[0][0]))\n",
    "#     break\n",
    "\n",
    "len(padding_mean_mfccs[100][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('padding_mean_mfccs_lstm.pkl', 'wb') as f:\n",
    "#     pickle.dump(padding_mean_mfccs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(padding_mean_mfccs, res, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1811, 13, 734)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train=np.array(X_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=np.transpose(X_test,(0,2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(892, 734, 13)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.transpose(X_train,(0,2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1811, 734, 13)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\karti\\Anaconda3\\lib\\site-packages\\tflearn\\layers\\recurrent.py:69: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\Users\\karti\\Anaconda3\\lib\\site-packages\\tflearn\\layers\\recurrent.py:681: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\karti\\Anaconda3\\lib\\site-packages\\tflearn\\objectives.py:66: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "net_lstm = tflearn.input_data([None, 734, 13])\n",
    "# net = tflearn.embedding(net, input_dim=10000, output_dim=128)\n",
    "net_lstm = tflearn.lstm(net_lstm, 32, dropout=0.8, return_seq= False)\n",
    "# net_lstm = tflearn.lstm(net_lstm, 128, dropout=0.4)\n",
    "net_lstm = tflearn.fully_connected(net_lstm,40, activation='softmax')\n",
    "net_lstm = tflearn.regression(net_lstm, optimizer='adam', learning_rate=0.001,\n",
    "                         loss='categorical_crossentropy')\n",
    "\n",
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\karti\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "model2_lstm = tflearn.DNN(net_lstm, tensorboard_verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 14999  | total loss: 0.81205 | time: 7.715s\n",
      "| Adam | epoch: 1000 | loss: 0.81205 - acc: 0.8989 -- iter: 1792/1811\n",
      "Training Step: 15000  | total loss: 0.75158 | time: 8.336s\n",
      "| Adam | epoch: 1000 | loss: 0.75158 - acc: 0.9028 -- iter: 1811/1811\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "model2_lstm.fit(X_train, y_train, n_epoch=1000, show_metric=True, batch_size=128,snapshot_step=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 16499  | total loss: 0.72067 | time: 9.262s\n",
      "| Adam | epoch: 100 | loss: 0.72067 - acc: 0.9201 -- iter: 1792/1811\n",
      "Training Step: 16500  | total loss: 0.65936 | time: 9.951s\n",
      "| Adam | epoch: 100 | loss: 0.65936 - acc: 0.9257 -- iter: 1811/1811\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "model2_lstm.fit(X_train, y_train, n_epoch=100, show_metric=True, batch_size=128,snapshot_step=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model2_lstm.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47045831032578683"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.argmax(y_train, axis=1)==np.argmax(y_pred, axis=1))/len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model2_lstm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41816143497757846"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.argmax(y_test, axis=1)==np.argmax(y_pred, axis=1))/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:C:\\Users\\karti\\Speech\\LibriSpeech\\dev-clean\\model_mean_mfccs_lstm_32.tflearn is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "model2_lstm.save('model_mean_mfccs_lstm_32.tflearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model2_lstm.load('model_mean_mfccs_lstm_32.tflearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\karti\\Anaconda3\\lib\\site-packages\\tflearn\\layers\\recurrent.py:69: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\Users\\karti\\Anaconda3\\lib\\site-packages\\tflearn\\layers\\recurrent.py:681: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\karti\\Anaconda3\\lib\\site-packages\\tflearn\\objectives.py:66: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "net_lstm_3 = tflearn.input_data([None, 734, 13])\n",
    "# net = tflearn.embedding(net, input_dim=10000, output_dim=128)\n",
    "net_lstm_3 = tflearn.lstm(net_lstm_3, 32, dropout=0.8, return_seq= False)\n",
    "# net_lstm = tflearn.lstm(net_lstm, 128, dropout=0.4)\n",
    "net_lstm_3 = tflearn.fully_connected(net_lstm_3,40, activation='softmax')\n",
    "net_lstm_3 = tflearn.regression(net_lstm_3, optimizer='adam', learning_rate=0.001,\n",
    "                         loss='categorical_crossentropy')\n",
    "\n",
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\karti\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "model3_lstm = tflearn.DNN(net_lstm_3, tensorboard_verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 14999  | total loss: 0.32604 | time: 9.340s\n",
      "| Adam | epoch: 1000 | loss: 0.32604 - acc: 0.9359 -- iter: 1792/1811\n",
      "Training Step: 15000  | total loss: 0.31553 | time: 10.134s\n",
      "| Adam | epoch: 1000 | loss: 0.31553 - acc: 0.9360 -- iter: 1811/1811\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "model3_lstm.fit(X_train, y_train, n_epoch=1000, show_metric=True, batch_size=128,snapshot_step=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 16499  | total loss: 0.28287 | time: 9.795s\n",
      "| Adam | epoch: 1100 | loss: 0.28287 - acc: 0.9361 -- iter: 1792/1811\n",
      "Training Step: 16500  | total loss: 0.26422 | time: 10.547s\n",
      "| Adam | epoch: 1100 | loss: 0.26422 - acc: 0.9409 -- iter: 1811/1811\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "model3_lstm.fit(X_train, y_train, n_epoch=100, show_metric=True, batch_size=128,snapshot_step=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model3_lstm.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3732744340143567"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.argmax(y_train, axis=1)==np.argmax(y_pred, axis=1))/len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model3_lstm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3374439461883408"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.argmax(y_test, axis=1)==np.argmax(y_pred, axis=1))/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:C:\\Users\\karti\\Speech\\LibriSpeech\\dev-clean\\model3_mean_mfccs_lstm_128.tflearn is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "model3_lstm.save('model3_mean_mfccs_lstm_128.tflearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\karti\\Speech\\LibriSpeech\\dev-clean\\model3_mean_mfccs_lstm_128.tflearn\n"
     ]
    }
   ],
   "source": [
    "model3_lstm.load('model3_mean_mfccs_lstm_128.tflearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\karti\\Anaconda3\\lib\\site-packages\\tflearn\\layers\\recurrent.py:69: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\Users\\karti\\Anaconda3\\lib\\site-packages\\tflearn\\layers\\recurrent.py:681: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\karti\\Anaconda3\\lib\\site-packages\\tflearn\\objectives.py:66: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "net_lstm = tflearn.input_data([None, 734, 13])\n",
    "# net = tflearn.embedding(net, input_dim=10000, output_dim=128)\n",
    "net_lstm = tflearn.lstm(net_lstm, 64, dropout=0.8, return_seq= False)\n",
    "# net_lstm = tflearn.lstm(net_lstm, 128, dropout=0.4)\n",
    "net_lstm = tflearn.fully_connected(net_lstm,40, activation='softmax')\n",
    "net_lstm = tflearn.regression(net_lstm, optimizer='adam', learning_rate=0.001,\n",
    "                         loss='categorical_crossentropy')\n",
    "\n",
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\karti\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "model_lstm = tflearn.DNN(net_lstm, tensorboard_verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 14999  | total loss: 0.79067 | time: 20.066s\n",
      "| Adam | epoch: 1000 | loss: 0.79067 - acc: 0.9343 -- iter: 1792/1811\n",
      "Training Step: 15000  | total loss: 0.71637 | time: 21.667s\n",
      "| Adam | epoch: 1000 | loss: 0.71637 - acc: 0.9401 -- iter: 1811/1811\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "model_lstm.fit(X_train, y_train, n_epoch=1000, show_metric=True, batch_size=128,snapshot_step=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 17999  | total loss: 0.52686 | time: 30.451s\n",
      "| Adam | epoch: 1200 | loss: 0.52686 - acc: 0.9549 -- iter: 1792/1811\n",
      "Training Step: 18000  | total loss: 0.47757 | time: 32.740s\n",
      "| Adam | epoch: 1200 | loss: 0.47757 - acc: 0.9586 -- iter: 1811/1811\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "model_lstm.fit(X_train, y_train, n_epoch=100, show_metric=True, batch_size=128,snapshot_step=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 19499  | total loss: 0.55841 | time: 26.699s\n",
      "| Adam | epoch: 1800 | loss: 0.55841 - acc: 0.9538 -- iter: 1792/1811\n",
      "Training Step: 19500  | total loss: 0.50571 | time: 28.773s\n",
      "| Adam | epoch: 1800 | loss: 0.50571 - acc: 0.9576 -- iter: 1811/1811\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "model_lstm.fit(X_train, y_train, n_epoch=100, show_metric=True, batch_size=128,snapshot_step=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_lstm.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6686913307564881"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.argmax(y_train, axis=1)==np.argmax(y_pred, axis=1))/len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_lstm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6289237668161435"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.argmax(y_test, axis=1)==np.argmax(y_pred, axis=1))/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:C:\\Users\\karti\\Speech\\LibriSpeech\\dev-clean\\model_mean_mfccs_lstm.tflearn is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "model_lstm.save('model_mean_mfccs_lstm.tflearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\karti\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\karti\\Speech\\LibriSpeech\\dev-clean\\model_mean_mfccs_lstm.tflearn\n"
     ]
    }
   ],
   "source": [
    "model_lstm.load('model_mean_mfccs_lstm.tflearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
